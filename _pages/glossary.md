---
title: "An ever expanding collection of ML & DL terminologies"
layout: single
classes: wide
toc: true
permalink: /glossary/
author_profile: true
taxonomy: glossary
entries_layout: list
header:
  image: "/assets/images/KM_glossary_19-October-2020.png"
  
---

# Activation Functions

## ReLU
  f(n) =
\begin{cases}
n/2,  & \text{if $n$ is even} \\
3n+1, & \text{if $n$ is odd}
\end{cases}

## Sigmoid

## Tanh

## Leaky ReLU


# Components of NN

## Activation Function

## Bias

## Neurons

## Weights


# Loss Functions

## MSE(Mean Squared Error)

## RMSE(Root Mean Squared Error)

## Log Loss